\chapter{Introduction} % Chapter title

\label{chapter:introduction} % For referencing the chapter elsewhere, use \ref{chapter:computational_neuro} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}
%----------------------------------------------------------------------------------------

\section{Status Quo}
\todo{→Literaturrecherche
Stand der Technik: Bisherige Lösungen des Problems und deren Grenzen}

\subsection{Multiple Query Optimization}
\todo{Here should be a concrete example of query optimization and afterwards extended by multi-query optimization.}
To explain what exactly multiple query optimization is, an everyday situation can be used as an example. Let's say that our entity $\mathcal{U}$ has a list $\mathcal{L}$ to go through. The list $\mathcal{L}$ consists of everything $\matchcal{U}$ has to buy at the groceries store. There are four elements in $\mathcal{L} = \left\{ \text{Apple}, \text{Pineapple}, \text{Beef}, \text{Wine}\right\}$. Each element $x \in \mathcal{L}$ has an isle in the store where it is located. To retrieve the item, $\mathcal{U}$ has to go to said isle and pick it up. By looking at the list, we can see that the elements “Pineapple” and “Apple” are both fruits, therefore situated at the same isle. To optimize the path through the store, $\mathcal{U}$ can combine the operation of retrieving the elements “Pineapple” and “Apple” so that he only needs to go to the fruit isle once. \par
In its essence, $\mathcal{U}$ did the optimization of a combinational problem by himself. In any relational database $\mathcal{D}$, the user $\mathcal{U}$ wants to retrieve information $\mathcal{I}$, which sits inside $\mathcal{D}$. For this, the request of information, referred to as \code{query}, is decomposed into single operations. Where the groceries store example had different isles and the path to reach them, $\mathcal{D}$ has stored tables it has to load into memory. Depending on the information the level of data normalization $\mathcal{D}$ has\cite{semantic_relational_data_model}, different tables have to be combined to result in the desired information $\mathcal{I}$. By taking into account the ever rising number of users a modern application serves\cite{uber_technologies_inc_uber_2022}, the situation arises where multiple queries are executed at the same time, hence the name \emph{Multiple Query Optimization}. If the user $\mathcal{U}$ is replaced by a robot $\mathcal{R}$ that can handle multiple requests at once, he too would be interested in combining operations to save time. So if multiple requests need fruits from the fruit isle, he could retrieve them at once – and save considerable runtime. \par
The problem of finding the optimal combination is of quadratic nature; which means that it usually takes $O(n^2)$ to find the combination with the most time savings. This been an ongoing problem to solve, with algorithms available that can find a \emph{good enough} solution in a usable timeframe.

\subsection{Quantum Neural Network}
Classification of data is a canonical problem in machine learning and has made great strides towards getting classical computers to classify data \cite{Killoran_2019,ClassificationWithQNN}. A reliable method for classifying data is offered by so-called artificial neural networks using supervised learning. Based on the training data, the artificial neural network learns to find a hypothesis that makes predictions that are as accurate as possible. To determine the accuracy, the learned hypothesis can be compared to test data whose solution is known to the classification. This supervised learning algorithm in its basic idea can also be executed on quantum computers. Currently, a common way to create, test and train artificial quantum neural networks is the hybrid classical-quantum algorithm, where only the artificial neural network is implemented as a quantum circuit and the optimization of the parameters is still done classically\cite{mccleanBarrenPlateausQuantum2018,Zhao_2021,schuld_SQMLmodelsAreKernelMethods,sim_expressibility_2019}.
There is currently no general implementation template for quantum neural networks, but various implementation examples and proposals with different classification applications and goals. Also, the available hardware and its access is limited and larger experiments with large datasets cannot yet be performed without a major effort. Nevertheless, in recent years, access to quantum computers has become steadily easier and quantum computation is currently undergoing a transformation from purely academic to industrially used technology\cite{schuldCircuitcentricQuantumClassifiers2020}. Furthermore ...\todo{finish sentences here} leverage the possibility quantum effects such as superposition, entanglement, and interference. The experiments hint at potential advantages, such as speed-ups in training, faster processing, parallelization and lesser complexity. ... but the question remains of whether quantum neural networks are more powerful than classical neural networks, is still open
\todo{What about Quantum SVM?}

\section{Goals}
\todo{Formuliert das Ziel der Arbeit
Achtung: Ziel und Aufgabe sind nicht zwingend dasselbe! Bitte sauber trennen.
Verweist auf die offizielle Auf-gabenstellung des/der Dozie-renden im Anhang}

\subsection{Multiple Query Optimization}
The goal of this paper is to evaluate the practicality of a quantum-based solution to solve the multiple query optimization problem. Using artificially generated data which mimics real life situations, a circuit is generated which then converges onto the optimal solution. For comparison, a different quantum solver is used and not only the results, but also the runtime assessed.

\subsection{Quantum Neural Network}
Another goal of this paper is to evaluate different variational quantum circuits which closely resemble Quantum Neural Networks for classification and further compare the results with the Quantum SVM approach done by NAME OF project thesis \todo{ref here}. We pre-trained the weights by a hybrid classical-quantum algorithm approach on quantum simulators using five different binary datasets of two different sizes and additionally the iris dataset with all datapoints and all of its three classes. Finally all quantum circuits are evaluated and analysed on freely available real Quantum hardware from IBM using the datasets and the pre-trained weights.

\clearpage
