\chapter{Discussion} % Chapter title

\label{chapter:discussion} % For referencing the chapter elsewhere, use \ref{chapter:computational_neuro} 


%----------------------------------------------------------------------------------------

\section{Multiple Query Optimization}

The first results from chapter \ref{chapter:results_mqo} show surprising results. In the case of figure \ref{figure:comparison_ml_noml_filtered_acc}, the ML optimized circuit achieves a better accuracy than the non-ML circuit. When compared to figure \ref{figure:comparison_ml_noml_parity_acc}, this was achieved exclusively through the change of the evaluation algorithm – instead of using the parity function, the filtered evaluation is used. Whilst not outperforming the non-ML circuit when run on real hardware, it manages to match it well enough.\par
When looking at the parity evaluation results from figure \ref{figure:comparison_ml_noml_parity_acc}, the non-ML circuit achieves a much lower accuracy than with the filtered evaluation. The ML optimized circuit behaves exactly as expected during training.\par
To further evaluate the stability of both circuits, a new problem space $\left|\mathcal{D}_{2\times2}\right| =\ 1000$ is generated and evaluated. Considering the results from the non-ML circuit with the filtered evaluation, this dataset is only evaluated with the filtered evaluation on the non-ML circuit, and achieves an accuracy inside the expectations, as seen in figure \ref{figure:blind_run_noml_circuit_acc}. The ML circuit is evaluated once with the filtered evaluation, and once with the parity evaluation. Figure \ref{figure:blind_run_ml_circuit_f_acc} and \ref{figure:blind_run_ml_circuit_p_acc} show the results that are, by comparison, well below the achieved results from figures \ref{figure:comparison_ml_noml_filtered_acc} and \ref{figure:comparison_ml_noml_parity_acc}. The resulting accuracy is lower on the unseen data – which is to be expected as the total achieved test accuracy, as stated in chapter \ref{chapter:mqo_machine_learning}, was only $~0.418$. When compared to the results from figures \ref{figure:comparison_ml_noml_filtered_acc} and \ref{figure:comparison_ml_noml_parity_acc}, the jump in accuracy from moving to the filtered evaluation with the ML circuit does not happen. In fact, there is even a loss of achieved accuracy to be observed. \par

To further evaluate the stability of the circuit and usability when moving towards real life situations, the dynamic problem generator from chapter \ref{chapter:mqo_data_acquisition} is used to generate datasets with ever-increasing complexity. These are used to automatically generate a circuit that can solve them. This circuit is based on the non-ML circuit, as it outperforms the ML variant by a considerable amount. \par
As overview, figure \ref{figure:overview_dynamic_problems} shows all the dynamic runs that were executed. The achieved accuracy gradually decreases with increased complexity. As can be seen in the figures \ref{figure:bars_dist_2_3} to \ref{figure:bars_dist_3_3_3}, the evaluated solutions and their distance to the best solution also behave comparable to the original circuit for the $2\times2$ problem, but start falling off with rising complexity. \par
This data can be interpreted as a sign that the circuit itself is robust and a good solution for the given problem. The behaviour explained in chapter \ref{chapter:mqo_data_acquisition}, more specifically in equations \ref{equation:normalization_range_1} to \ref{equation:normalization_range_forth_pi} appears to need adaptation with increased complexity. As more and more gates are applied to a given qubit, the change to the probabilities sum up, the described \emph{tipping point} might be traversed and therefore lowering the probabilities of measuring the actual cheapest combination. Nonetheless, even the most complex run from figure \ref{figure:bars_dist_3_3_3} does yield the best solution most of the time. \par
To really define whether the solution is good enough to use or not, one has to define where the line is drawn between time savings and time spent computing the best solution. As shown in chapter \ref{chapter:mqo_manual_validation} with figure \ref{figure:correlation_accuracy_shots}, adding the probabilities of all \emph{acceptable} combinations can lead to a high enough total probability, and therefore, savings of execution time.

\subsection{Comparison QAOA Solution}
The solution proposed by Fankhauser et al.\cite{fankhauser_multiple_2021} offers a peak accuracy of $59\%$ for a problem space $\mathcal{D}_{2\times2}$, as shown in their figure 13. This is, by a substantial amount, below the achieved results in this thesis for the non-ML circuit, as per figure \ref{figure:comparison_ml_noml_filtered_acc}. Even so, if the 2nd best solution is also within acceptance, which yields a total accuracy of $~90\%$ per figure \ref{figure:noml_rhw_dist}. \par
Additionally, the paper also goes into detail about its runtime, stating a runtime of $O(I · (PQ)^2)$. First, As $I$ stands for the number of iterations the algorithm goes through \emph{per problem}, the proposed circuit already offers one speed up in comparison, as it only needs to be evaluated once\footnote{Evaluated once means measurement with $n$ shots}. \par
By following the given example in the paper of assuming outside algorithms to be $O(1)$ (in our case the normalization step), only the circuit is needed for the runtime evaluation. The first segment of the circuit consists of single, non entangled gates per qubit, which can be run in parallel, and therefore translate to a runtime of $O(1)$.
The layer afterwards consist of the possible savings $n$ plans could combine into. For a quadratic problem space, i.e. $\mathcal{D}_{2\times2}$, this would translate into $2\times2 =\ 4$ combinations, so $\mathcal{Q}\times\mathcal{P}$. Of course, real life situation will not always yield possible combinations for each plan, which means that $O(QP)$ should be seen as an upper bound. In addition, this assumes that there are no gates that can be executed at the same time. In circuit \ref{circuit:noml_dyn_problem} it is easy to see that by moving certain entanglement gates around, one could execute them at the same time, therefore saving time. \par
It is important to note that whilst the non-ML circuit has a supposed runtime of $O(QP)$, it is unclear from the literature if the $O$-notation can be used in quantum computing as it is used in classical computing.

\subsection{ML Optimization}
Results indicate that the ML optimized circuit cannot, in this form, match the non-ML variant. Whilst there was a substantial jump in accuracy when moving from the parity evaluation to the filtered evaluation, as per figures \ref{figure:comparison_ml_noml_filtered_acc} and \ref{figure:comparison_ml_noml_parity_acc}, this can only be attributed to a stroke of luck rather than concrete evidence. What it does point out is that there is still potential when it comes to quantum based machine learning, once learning becomes available with custom evaluation functions. \par


\subsection{Outlook}
As promising as the results are, these are still \emph{only} achieved in a simulated problem space. Further steps should include the collection and usage of query-plan data from real systems and evaluating those. The result can then be compared with the absolute best solution, as well as the solution selected by the classical algorithm. \par
For more complex problems, experimentation with normalization ranges has to be conducted and a function evaluated, that can compute the optimal range depending on the complexity\par
In the case of the ML circuit, enhancing it with additional gates that \emph{lower} the probabilities of measuring a solution to a combination that is not possible.

\newpage

\section{Quantum Neural Network}
